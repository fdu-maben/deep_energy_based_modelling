/var/spool/slurm/d/job130563/slurm_script: line 13: activate: No such file or directory
[rank: 0] Seed set to 42
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
HPU available: False, using: 0 HPUs
[rank: 0] Seed set to 42
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
[rank: 1] Seed set to 42
[rank: 2] Seed set to 42
[rank: 3] Seed set to 42
[rank: 1] Seed set to 42
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
[rank: 2] Seed set to 42
[rank: 3] Seed set to 42
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]

  | Name | Type     | Params | Mode  | In sizes       | Out sizes     
----------------------------------------------------------------------------
0 | cnn  | CNNModel | 1.5 M  | train | [1, 3, 32, 32] | [[1], [1, 10]]
----------------------------------------------------------------------------
1.5 M     Trainable params
0         Non-trainable params
1.5 M     Total params
5.869     Total estimated model params size (MB)
109       Modules in train mode
0         Modules in eval mode
slurmstepd: error: *** JOB 130563 ON g02n05 CANCELLED AT 2025-08-04T15:24:05 ***
[rank: 0] Received SIGTERM: 15
[rank: 3] Received SIGTERM: 15
[rank: 1] Received SIGTERM: 15
[rank: 3] Received SIGTERM: 15
--- Logging error ---
[rank: 2] Received SIGTERM: 15
[rank: 2] Received SIGTERM: 15
